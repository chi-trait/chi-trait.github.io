(this["webpackJsonpchi-trait"]=this["webpackJsonpchi-trait"]||[]).push([[0],{51:function(e,a,i){},65:function(e,a,i){},66:function(e,a,i){},77:function(e,a,i){},78:function(e,a,i){},79:function(e,a,i){},80:function(e,a,i){},81:function(e,a,i){},82:function(e,a,i){},83:function(e,a,i){},84:function(e,a,i){},85:function(e,a,i){"use strict";i.r(a);var n,t=i(0),s=i.n(t),r=i(8),o=i(57),c=i(128),l=i(43),d=i(42),p=i(22),h=i(10),u=(i(65),i(15)),m=i(18),f=i(114),g=i(129),b=i(131),y=i(117),j=i(118),v=i(119);!function(e){e.about="About",e.cfp="Call for Papers",e.schedule="Schedule"}(n||(n={}));i(66);var w=i(120),x=i(121),A=i(1),I=Object(f.a)((function(e){return{sectionDesktop:Object(m.a)({display:"none"},e.breakpoints.up("md"),{display:"flex"}),sectionMobile:Object(m.a)({display:"flex"},e.breakpoints.up("md"),{display:"none"})}})),k=function(e){e.logo;var a=s.a.useState(null),i=Object(u.a)(a,2),t=i[0],r=i[1],o=Boolean(t),c=s.a.useState(null),l=Object(u.a)(c,2),d=l[0],h=l[1],m=Boolean(d),f=s.a.useState(2023),k=Object(u.a)(f,2),_=k[0],O=k[1],S=function(){r(null)},H=function(){h(null)},T="primary-search-account-menu-mobile",C="primary-search-account-menu-year",M=Object(A.jsx)(g.a,{anchorEl:d,anchorOrigin:{vertical:"top",horizontal:"right"},id:C,keepMounted:!1,transformOrigin:{vertical:"top",horizontal:"right"},open:m,onClose:H,children:[2022,2023].map((function(e){return Object(A.jsx)(p.b,{className:"menu-option",exact:!0,to:"/".concat(e),onClick:H,children:Object(A.jsx)(b.a,{onClick:function(){O(e),H()},children:e},e)})}))}),N=Object(A.jsx)(g.a,{anchorEl:t,anchorOrigin:{vertical:"top",horizontal:"right"},id:T,keepMounted:!1,transformOrigin:{vertical:"top",horizontal:"right"},open:o,onClose:S,children:Object.keys(n).map((function(e){return Object(A.jsx)(p.b,{className:"menu-option",exact:!0,to:"/".concat(_,"/").concat(e),onClick:S,children:Object(A.jsx)(b.a,{children:n[e]},e)})}))}),P=I();return Object(A.jsxs)(y.a,{className:"app-header",position:"sticky",children:[Object(A.jsxs)(j.a,{variant:"dense",className:"toolbar",children:[Object(A.jsx)("span",{children:Object(A.jsxs)(v.a,{"aria-label":"show more","aria-controls":C,"aria-haspopup":"true",onClick:function(e){h(e.currentTarget)},color:"inherit",children:[Object(A.jsx)("span",{children:Object(A.jsx)("img",{className:"logo",src:"".concat("","/images/logo_word_white.png")})}),Object(A.jsxs)("div",{className:"year",children:["".concat(_),Object(A.jsx)(w.a,{})]})]})}),Object(A.jsx)("nav",{className:P.sectionDesktop,children:Object(A.jsx)("ul",{children:Object.keys(n).map((function(e){return Object(A.jsx)("li",{className:"option",children:Object(A.jsx)(p.b,{exact:!0,to:"/".concat(_,"/").concat(e),children:n[e]})},e)}))})}),Object(A.jsx)("div",{className:P.sectionMobile,children:Object(A.jsx)(v.a,{"aria-label":"show more","aria-controls":T,"aria-haspopup":"true",onClick:function(e){r(e.currentTarget)},color:"inherit",children:Object(A.jsx)(x.a,{})})})]}),N,M]})},_=(i(51),i(132)),O=i(124),S=(i(77),i(4)),H=i(122),T=i(123),C=function(e){var a=e.organizer,i=s.a.useState(!1),n=Object(u.a)(i,2),t=n[0],r=n[1],o=Object(A.jsxs)(A.Fragment,{children:[a.webpage&&Object(A.jsx)("a",{href:a.webpage,children:Object(A.jsx)(H.a,{className:"iconlink",color:"primary",fontSize:"small"})}),a.twitter&&Object(A.jsx)("a",{href:a.twitter,children:Object(A.jsx)(T.a,{className:"iconlink",color:"primary",fontSize:"small"})})]});return Object(A.jsxs)("div",{onMouseOut:function(){return r(!1)},onMouseOver:function(){r(!0)},className:"entry",children:[Object(A.jsx)(_.a,{className:"avatar",alt:a.name,src:"".concat("","/images/").concat(a.img)}),Object(A.jsxs)("div",{children:[Object(A.jsxs)("div",{className:Object(S.a)("description",{visible:t}),children:[Object(A.jsx)("div",{children:o}),a.description]}),Object(A.jsx)("div",{className:"name",children:a.name}),Object(A.jsx)("div",{className:"affiliation",children:a.affliation})]})]})},M=function(e){var a=e.organizers;return Object(A.jsx)(O.a,{container:!0,spacing:3,className:"organizer-list",children:a.map((function(e){return Object(A.jsx)(O.a,{item:!0,lg:3,md:3,sm:3,xs:12,children:Object(A.jsx)(C,{organizer:e})},e.name)}))})},N=(i(78),function(e){var a=e.members;return 0===a.length?Object(A.jsx)("i",{children:"To be updated!"}):Object(A.jsx)("div",{className:"committee-list",children:a.map((function(e,a){return Object(A.jsxs)("div",{className:"member",children:[Object(A.jsx)("span",{className:"name",children:e.name}),Object(A.jsx)("span",{className:"affiliation",children:e.affiliation})]},e.name)}))})}),P=(i(79),function(e){var a=e.cfp;return Object(A.jsxs)("div",{className:"cfp-text",children:[Object(A.jsxs)(O.a,{container:!0,spacing:3,className:"info-block-wrapper",children:[Object(A.jsx)(O.a,{item:!0,md:7,sm:12,children:Object(A.jsxs)("div",{className:"info-block",children:[Object(A.jsx)("div",{className:"info-title",children:"Important Dates"}),a.dates.map((function(e,a){return Object(A.jsxs)("div",{children:[Object(A.jsxs)("div",{className:"row",children:[Object(A.jsx)("div",{className:"row-key long",children:e.type}),Object(A.jsx)("div",{className:Object(S.a)("row-value",{"passed-date":e.isPassed}),children:e.date})]}),e.description&&Object(A.jsx)("div",{className:"description",children:e.description})]},a)}))]})}),Object(A.jsx)(O.a,{item:!0,md:5,sm:12,children:Object(A.jsxs)("div",{className:"info-block",children:[Object(A.jsx)("div",{className:"info-title",children:"Submission format"}),Object(A.jsxs)("div",{className:"row",children:[Object(A.jsx)("div",{className:"row-key",children:"Platform"}),Object(A.jsx)("a",{className:"row-value",href:a.submit.platform.url,children:a.submit.platform.name})]}),Object(A.jsxs)("div",{className:"row",children:[Object(A.jsx)("div",{className:"row-key",children:"Format"}),Object(A.jsx)("div",{className:"row-value",children:a.submit.format})]})," ",Object(A.jsxs)("div",{className:"row",children:[Object(A.jsx)("div",{className:"row-key",children:"Types"}),Object(A.jsx)("div",{className:"row-value",children:a.submit.type})]})," "]})})]}),Object(A.jsx)("div",{className:"info-title",children:"Description"}),Object(A.jsx)("p",{children:a.description}),Object(A.jsx)("p",{children:"Themes include, but are not limited to:"}),Object(A.jsx)("ul",{children:a.themes.map((function(e,a){return Object(A.jsx)("li",{children:e},a)}))})]})}),D=(i(80),i(125)),U=i(133),R=function(e){e.schedule;var a=e.papers,i=e.year;return console.log(a),Object(A.jsx)(A.Fragment,{children:a.map((function(e){return Object(A.jsxs)("div",{className:"paper",children:[Object(A.jsxs)("div",{className:"paper-title",children:[e.type in["short","long"]&&Object(A.jsx)(U.a,{label:e.type+(e.is_encore?", encore":""),color:"secondary",size:"small",variant:"outlined",className:"paper-type"}),e.title,Object(A.jsx)("a",{href:"".concat("","/papers/CHI_TRAIT_").concat(i,"_Paper_").concat(e.paper_id,".pdf"),children:Object(A.jsx)(D.a,{fontSize:"small",className:"icon"})})]}),Object(A.jsx)("div",{className:"paper-author",children:e.authors})]},e.paper_id)}))})},z=function(e){var a=e.schedule,i=e.papers,n=e.year,s=Object(t.useState)("paper"===a.type),r=Object(u.a)(s,2),o=(r[0],r[1],null),c=null;return c="keynote"===a.type||"panel"===a.type||"paper"===a.type?Object(A.jsxs)("span",{children:[a.format,"; Moderator: ",a.leader]}):Object(A.jsx)("span",{children:a.format}),o="paper"===a.type||"poster"===a.type?Object(A.jsx)(R,{schedule:a,year:n,papers:i.filter((function(e){return e.session_id===a.sessionId})).sort((function(e,a){return e.paper_order-a.paper_order}))}):Object(A.jsx)("span",{children:a.description}),Object(A.jsxs)("div",{className:"schedule",children:[Object(A.jsxs)("div",{className:"schedule-title",children:[Object(A.jsxs)("span",{className:"time",children:[a.start," -- ",a.end]}),Object(A.jsx)("span",{className:"theme",children:a.title}),Object(A.jsx)("span",{className:"format",children:c})]}),Object(A.jsx)("div",{className:"schedule-description",children:o})]},JSON.stringify(a))},E=function(e){var a=e.schedules,i=e.papers,n=e.year;return 0===a.length?Object(A.jsx)("i",{children:"To be updated!"}):Object(A.jsx)("div",{className:"schedule-list",children:a.map((function(e,a){return Object(A.jsx)(z,{schedule:e,papers:i,year:n},a)}))})},W=(i(81),function(e){var a=e.overview;return Object(A.jsx)(A.Fragment,{children:Object(A.jsxs)("div",{style:{},className:"landing",children:[Object(A.jsxs)("div",{className:"landing-title",children:[Object(A.jsx)("img",{className:"landing-logo",src:"".concat("","/images/").concat(a.logoWithWord)})," ",Object(A.jsxs)("p",{className:"landing-description",children:[Object(A.jsx)("b",{children:a.fullName}),", at ",a.confName," ",a.year]})]}),Object(A.jsx)("img",{className:"img",src:"".concat("","/images/").concat(a.backgroundImg)})]})})}),L=(i(82),i(126)),B=function(e){var a=e.overview,i=e.cfp;return Object(A.jsx)(A.Fragment,{children:Object(A.jsxs)("div",{className:"about-div",children:[Object(A.jsxs)(O.a,{container:!0,spacing:3,className:"dates",children:[i.dates.map((function(e,a){return"Camera ready"===e.type?null:Object(A.jsx)(O.a,{item:!0,md:3,sm:6,xs:12,children:Object(A.jsxs)("div",{className:"col",children:[Object(A.jsx)("span",{className:"col-key",children:e.type}),Object(A.jsx)("div",{className:Object(S.a)("col-value",{"passed-date":e.isPassed}),children:e.date})]})},a)})),Object(A.jsx)(O.a,{item:!0,md:3,sm:6,xs:12,children:Object(A.jsxs)("div",{className:"col",children:[Object(A.jsx)("span",{className:"col-key",children:"contact"}),Object(A.jsxs)("div",{className:"col-value",children:[Object(A.jsx)(L.a,{className:"icon",fontSize:"small",color:"primary"})," ",Object(A.jsx)("a",{href:"mailto:".concat(a.contact),children:a.contact})]})]})})]}),Object(A.jsx)("div",{className:"description",children:a.description})]})})},G=i(127),K=(i(83),function(e){var a=e.speaker,i=s.a.useState(!1),n=Object(u.a)(i,2);n[0],n[1];return Object(A.jsxs)("div",{className:"speaker",children:[Object(A.jsx)(_.a,{className:"avatar",alt:a.name,src:"".concat("","/images/").concat(a.img)}),Object(A.jsxs)("div",{children:[Object(A.jsxs)("b",{className:"name",children:[Object(A.jsx)(U.a,{label:a.type,color:"primary",size:"small",variant:"outlined"}),Object(A.jsx)("a",{href:a.webpage,style:{marginLeft:10},children:a.name})]}),", ",Object(A.jsx)("i",{className:"affiliation",children:a.affliation}),Object(A.jsx)("p",{children:a.description})]})]})}),J=function(e){var a=e.speakers;return 0===a.length?Object(A.jsx)("i",{children:"To be updated!"}):Object(A.jsx)("div",{className:"speaker-list",children:a.map((function(e){return Object(A.jsxs)(A.Fragment,{children:[Object(A.jsx)(K,{speaker:e},e.name),Object(A.jsx)(G.a,{className:"divider"},e.name)]})}))})},F=i(130),Z=function(e){var a=e.metas,i=e.types,n=Object(h.f)().year;void 0!==n&&"undefined"!=n||(n=2023);var t=a.find((function(e){return e.overview.year===n}));return void 0===t?Object(A.jsx)("div",{children:"Not Found"}):Object(A.jsxs)("div",{children:[Object(A.jsx)(W,{overview:t.overview}),Object(A.jsxs)("div",{className:"app-main",children:[t.announce&&Object(A.jsx)(F.a,{severity:"warning",className:"warning",children:t.announce}),i.includes("about")&&Object(A.jsxs)("div",{className:"section",children:[Object(A.jsx)("div",{className:"title",children:"About"}),Object(A.jsx)(B,{overview:t.overview,cfp:t.cfp})]}),i.includes("schedule")&&Object(A.jsxs)("div",{className:"section",children:[Object(A.jsxs)("div",{className:"title",children:["Schedule"," ",Object(A.jsxs)("small",{children:["in ",Object(A.jsx)("b",{children:t.overview.timezone})]})]}),Object(A.jsx)(E,{schedules:t.schedule,papers:t.papers,year:Number(t.overview.year)})]}),i.includes("schedule")&&Object(A.jsxs)("div",{className:"section",children:[Object(A.jsx)("div",{className:"title",children:"Speakers & Panelists"}),Object(A.jsx)(J,{speakers:t.speakers})]}),i.includes("cfp")&&Object(A.jsxs)("div",{className:"section",children:[Object(A.jsx)("div",{className:"title",children:"Call for Papers"}),Object(A.jsx)(P,{cfp:t.cfp})]}),i.includes("organizers")&&Object(A.jsxs)("div",{className:"section",children:[Object(A.jsx)("div",{className:"title",children:"Organizers"}),Object(A.jsx)(M,{organizers:t.organizers})]}),i.includes("committee")&&Object(A.jsxs)("div",{className:"section",children:[Object(A.jsx)("div",{className:"title",children:"Program Committees"}),Object(A.jsx)(N,{members:t.pcs})]})]})]},i.join("-"))};i(84);function V(e){var a=e.contact;return Object(A.jsxs)("footer",{className:"footer",children:["If you have any questions, please contact us at"," ",Object(A.jsx)(L.a,{className:"icon",fontSize:"small",color:"primary"})," ",Object(A.jsx)("a",{href:"mailto:".concat(a),children:a})]})}var Y={overview:{contact:"trait2023@easychair.org",timezone:"GMT+2, Hamburg, Germany time",acronym:"TRAIT",year:"2023",fullName:"Workshop on Trust and Reliance in AI-Assisted Tasks",description:Object(A.jsxs)(A.Fragment,{children:[Object(A.jsxs)("p",{children:["As humans increasingly interact (and even collaborate) with AI systems during decision-making, creative exercises, and other tasks,appropriatetrust and reliance are necessary to ensure proper usage and adoption of these systems. Specifically, people should understand when to trust or rely on an algorithm's outputs and when to override them. While significant research focus has aimedto measure and promote trust in human-AI interaction, the field lacks synthesized definitions and understanding of results acrosscontexts. Indeed, conceptualizing trust and reliance, and identifying the best ways to measure these constructs and effectively shapethem in human-AI interactions remains a challenge. Formerly the workshop on"," ",Object(A.jsx)("i",{children:"Trust and Reliance in AI-Human Teams"}),", this sequel workshop aims to"," ",Object(A.jsx)("b",{className:"text-highlight",children:"establish building appropriate trust and reliance on (imperfect) AI systems as a vital, yet under-explored research problem."})]}),Object(A.jsxs)("p",{children:[" ","The workshop will provide a venue for exploring three broad aspects related to human-AI trust:"," "]}),Object(A.jsxs)("ul",{children:[Object(A.jsxs)("li",{children:["How do we clarify"," ",Object(A.jsx)("span",{className:"text-highlight",children:"definitions and frameworks"})," ","relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)?"]}),Object(A.jsxs)("li",{children:["How do we ",Object(A.jsx)("span",{className:"text-highlight",children:"measure"})," trust and reliance?"]}),Object(A.jsxs)("li",{children:["How do we ",Object(A.jsx)("span",{className:"text-highlight",children:"shape"})," trust and reliance?"," "]})]}),Object(A.jsx)("p",{children:Object(A.jsxs)("b",{children:["The workshop will build on the success from running it at CHI 2022 with a focus on"," ",Object(A.jsx)("span",{className:"text-highlight",children:"Learning from Practice"})," --- how can we better tie theory-building to real-life use cases?"]})}),Object(A.jsx)("p",{children:"As these problems and solutions involving humansand AI are interdisciplinary in nature, we invite participants with expertise in HCI, AI, ML, psychology, and social science, or otherrelevant fields to foster closer communications and collaboration between multiple communities."})]}),backgroundImg:"background.png",confLogoImg:"chi2022.png",logoImg:"logo.png",logoWithWord:"logo_word.png",confName:"CHI"},organizers:[{name:"Gagan Bansal",affliation:"Microsoft Research",webpage:"https://gagb.github.io/",img:"gagan.png",twitter:"https://twitter.com/bansalg_",description:"Gagan is a a Senior Researcher at Microsoft Research, Redmond. He received his Ph.D. degree from the Allen School of Computer Science and Engineering at the University of Washington, Seattle. He conducts interdisciplinary research on Artificial Intelligence and Human-Computer Interaction with focus on developing human-centered AI systems for augmenting people."},{name:"Zana Bu\xe7inca",affliation:"Harvard University",twitter:"https://twitter.com/ZanaBucinca",webpage:"https://hci.seas.harvard.edu/people/zana-bu%C3%A7inca",img:"zana.png",description:"Zana is a Ph.D. Candidate at Harvard University. Her research lies at the intersection of Human-Computer Interaction and Artificial Intelligence. Informed by cognitive science theories, Zana designs, builds, and evaluates AI for decision-making support."},{name:"Ken Holstein",twitter:"https://twitter.com/d19fe8",affliation:"Carnegie Mellon University",webpage:"https://www.thecoalalab.com/kenholstein",img:"kenneth.png",description:"Ken is an Assistant Professor in Human-Computer Interaction at Carnegie Mellon University. His research interests lie at the intersection of HCI, AI, design, and cognitive science, focusing on the design, development, and evaluation of human-AI collaborative systems in complex social contexts."},{name:"Jessica Hullman",twitter:"https://twitter.com/JessicaHullman",affliation:"Northwestern University",webpage:"http://users.eecs.northwestern.edu/~jhullman/",img:"jessica.png",description:"Jessica is an Associate Professor of Computer Science at Northwestern University. Her research looks at how to design, evaluate, coordinate, and think about visual representations of data and model predictions for inference, decision making, and communication, including the effects of visualizing uncertainty on belief updating and potential for behaviorally induced feedback loops in visualizing model predictions in strategic settings. "},{name:"Alison Smith-Renner",affliation:"Dataminr",webpage:"https://alisonmsmith.github.io/",twitter:"https://twitter.com/alison_m_smith",img:"alison.png",description:"Alison is a Senior Research Scientist at Dataminr. Her research interests lie at the intersection of AI and HCI, focusing on transparency and control for human-in-the-loop systems to engender appropriate trust and improve human performance. Alison received her Ph.D. from the University of Maryland, College Park. She has organized various workshops on explainable AI and human-centered ML, including at IUI, CHI, and TEI, and she has held senior committee roles at IUI."},{name:"Simone Stumpf",twitter:"https://twitter.com/DrSimoneStumpf",affliation:"University of Glasgow",webpage:"https://www.gla.ac.uk/schools/computing/staff/simonestumpf/",img:"simone.png",description:"Simone is a Reader in Responsible and Interactive AI at University of Glasgow, UK. She has a long-standing research focus on user interactions with machine learning systems. Her work has contributed to shaping the field of Explainable AI (XAI) through the Explanatory Debugging approach to interactive machine learning, providing design principles for crafting explanations. She has been a member of the organising committee of the ExSS workshop at IUI, and has held senior committee roles at CHI, IUI and EICS conferences. "},{name:"Sherry Tongshuang Wu",twitter:"https://twitter.com/tongshuangwu",affliation:"University of Washington",webpage:"http://cs.cmu.edu/~sherryw",img:"sherry.png",description:"Sherry is an Assistant Professor in the Human-Computer Interaction Institute at Carnegie Mellon University. Her research lies at the intersection of Human-Computer Interaction and Natural Language Processing, aiming to design, evaluate, build, and interact with AI systems that are compatible with actual human goals. Before joining CMU, Sherry received her Ph.D. degree from the University of Washington."}],cfp:{description:Object(A.jsxs)(A.Fragment,{children:[Object(A.jsx)("div",{children:"As humans increasingly interact with AI systems during decision-making, creative tasks, and other workflows, appropriate trust and reliance are necessary to ensure proper usage and adoption of these systems. For example, people should understand when to trust or rely on an algorithm's outputs and when to override them. While significant research focus has aimed to measure and promote trust in human-AI interaction, the field lacks synthesized results across contexts, formalized key concepts, and definitions. The workshop will provide a venue to explore three broad aspects related to human-AI trust: (1) How do we clarify definitions and frameworks relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)? (2) How do we measure trust and reliance? And, (3) How do we shape trust and reliance?\""}),Object(A.jsx)("p",{children:"We welcome work that discusses interactions between one human and AI, as well as those that involve multiple humans / multiple AI systems."}),Object(A.jsxs)("p",{children:[Object(A.jsxs)("b",{children:["We welcome submissions to either the"," ",Object(A.jsx)("span",{className:"text-highlight",children:"research"})," track, or the"," ",Object(A.jsx)("span",{className:"text-highlight",children:"industry"})," track."]})," ","Research track papers may present a new position, summarize existing research, or discuss in-progress works. Industrial track papers should focus more on providing industry perspective, e.g., How do practitioners in startups, non-profits, etc. think about trust and reliance on AI models? How do they view the theoretical work and case studies coming out of academia?"]}),Object(A.jsxs)("p",{children:["Submission will be reviewed by PC members, in a"," ",Object(A.jsx)("b",{children:"single-blind manner"})," --- The authors should feel free to reveal your identity in the submission, but they will not know who the reviewers are."]})]}),themes:["Definitions of trust and reliance","Human-human trust and lessons from social sciences","Qualitative (e.g., user reflection) and quantitative methods (e.g., usage, adoption, human-AI performance, etc.) for evaluating trust and reliance.","Tradeoffs with other objectives (e.g., human-AI performance, creativity, etc)","Solutions (and their limitations) for promoting appropriate trust (e.g., XAI, control mechanisms, human agency, communicating uncertainty etc).","Safety mechanisms for when trust is broken."],dates:[{date:"February 23, 2023, 11:59 PM (Anywhere on Earth)",isPassed:!0,type:"Submission",description:"Submission will be reviewed by PC members, in a single-blind manner."},{date:"March 10, 2023",type:"Notification",isPassed:!0},{date:"April 11, 2023",type:"Camera ready",isPassed:!1,description:"Accepted papers will be non-archival, and will be posted on this website & shared via social media."},{date:"TBD (between April 23-28, 2023)",type:"Workshop",isPassed:!1,description:"At least one author must register and attend the hybrid workshop."}],submit:{platform:{name:"EasyChair",url:"https://easychair.org/conferences/?conf=trait2023"},format:Object(A.jsxs)("span",{children:[" ","ACM ",Object(A.jsx)("b",{children:"single"})," column, ",Object(A.jsx)("b",{children:"4-10"})," pages, excluding references. [",Object(A.jsx)("a",{href:"https://www.acm.org/binaries/content/assets/publications/taps/acm_submission_template.docx",children:"Word"}),"][",Object(A.jsx)("a",{href:"https://www.acm.org/binaries/content/assets/publications/consolidated-tex-template/acmart-primary.zip",children:"LaTeX"}),"][",Object(A.jsx)("a",{href:"https://www.overleaf.com/latex/templates/acm-conference-proceedings-master-template/pnrfvrrdbfwt",children:"Overleaf"}),"] If you use latex, please use: ",Object(A.jsx)("code",{children:"documentclass [manuscript, review, anonymous] {acmart}"})]}),type:'Position paper; Summarize existing research; Provide industry perspective; In-progress work; "encore" submissions of highly-relevant conference/journal papers.'}},pcs:[{name:"Vivian Lai",affiliation:"Visa Research"},{name:"Jennifer Wortman Vaughan",affiliation:"Microsoft"},{name:"Tim\tMiller",affiliation:"The University of Melbourne"},{name:"Philipp\tWintersberger",affiliation:"Visual Computing"},{name:"Ming Yin",affiliation:"Purdue University"},{name:"Brian\tLim",affiliation:"National University of Singapore"},{name:"Hal Daume Iii",affiliation:"Microsoft"},{name:"Anna Kawakami",affiliation:"Carnegie Mellon University"},{name:"Shi Feng",affiliation:"University of Chicago"},{name:"Jakob Schoeffer",affiliation:"Karlsruhe Institute of Technology (KIT)"},{name:"Alon Jacovi",affiliation:"Bar-Ilan University"},{name:"Quan Ze Chen",affiliation:"University of Washington"},{name:"Max Schemmer",affiliation:"Karlsruhe Institute of Technology"},{name:"Valerie Chen",affiliation:"Carnegie Mellon University"},{name:"Zelun Tony Zhang",affiliation:"fortiss GmbH"},{name:"\xc1ngel Alexander Cabrera",affiliation:"Carnegie Mellon University"},{name:"Elena Glassman",affiliation:"Harvard University"},{name:"Maria De-Arteaga",affiliation:"University of Texas at Austin"},{name:"Krzysztof Gajos",affiliation:"Harvard University"},{name:"Marissa Radensky",affiliation:"University of Washington"},{name:"Aaron Springer",affiliation:"Google"},{name:"Retno Larasati",affiliation:"The Open University"},{name:"Isaac Lage",affiliation:"Harvard University"},{name:"Patrick Hemmer",affiliation:"Karlsruhe Institute of Technology"},{name:"Ella Glikson",affiliation:"Bar Ilan University"},{name:"Elizabeth Watkins",affiliation:"Intelligent Systems Research, Intel Labs"},{name:"Michael Bernstein",affiliation:"Stanford University"},{name:"Zahra Ashktorab",affiliation:"University of Maryland"},{name:"Vera Liao",affiliation:"Microsoft Research"},{name:"Madeleine Grunde-McLaughlin",affiliation:"University of Washington"},{name:"Michael Terry",affiliation:"Google"},{name:"Joyce Zhou",affiliation:"Cornell University"}],schedule:[{start:"09:00",end:"09:15",title:"Welcome",leader:"Zana Bu\xe7inca and Alison Smith-Renner",format:"Hybrid",type:"break"},{start:"09:15",end:"10:00",title:"Keynote from Carrie Cai and Michael Terry",leader:"Simone Stumpf and Sherry Wu",format:"Hybrid",type:"keynote"},{start:"10:00",end:"10:30",sessionId:0,title:"Paper Session 1 - Modeling Human Trust and Reliance",leader:"Ken Holstein",format:"Hybrid, slack Q&A",type:"paper"},{start:"10:30",end:"11:00",title:"Coffee Break",format:"",type:"break"},{start:"11:00",end:"11:30",sessionId:1,title:"Paper Session 2 - Trust-Calibrating Interfaces",leader:"Alison Smith-Renner",format:"Hybrid, slack Q&A",type:"paper"},{start:"11:30",end:"11:55",sessionId:2,title:"Paper Session 3 - Trust for Fairness and Ethics",leader:"Zana Bu\xe7inca",format:"Hybrid, slack Q&A",type:"paper"},{start:"11:55",end:"12:30",title:"Posters: Break out rooms",sessionId:-1,format:"Virtual with in-person option (ie. huddle around a table for in-person poster presenters)",type:"poster"},{start:"12:30",end:"14:00",title:"Lunch",format:"on your own",type:"break"},{start:"14:00",end:"14:45",title:"Group activity: State of the art and future directions",leader:"Simone Stumpf",format:"Hybrid (in person and breakout rooms)",type:"group"},{start:"14:45",end:"15:30",title:"Panel: Stephanie Ballard, Pamela Mishkin, Devansh Saxena, Aaron Halfaker",leader:"Jessica Hullman",format:"Hybrid",type:"panel"},{start:"15:30",end:"15:45",title:"Coffee Break",format:"",type:"break"},{start:"15:45",end:"16:45",title:"Group activity: discussion of panel content",leader:"Ken Holstein",format:"Hybrid (in person and breakout rooms)",type:"group"},{start:"16:45",end:"17:00",title:"Closing Remarks",leader:"Gagan Bansal and Alison Smith-Renner",format:"Hybrid",type:"break"}],speakers:[],papers:[{paper_id:20,session_id:-1,paper_order:-1,title:"The Importance of Trust and Acceptance in User-Centred XAI - Practical Implications for a Manufacturing Scenario",authors:"Erika Puiutta, Larbi Abdenebaoui and Susanne Boll",type:"Poster"},{paper_id:46,session_id:2,paper_order:0,title:"The Impact of Explanations on Fairness in Human-AI Decision Making: Protected vs Proxy Features",authors:"Navita Goyal, Connor Baumler, Tin Nguyen and Hal Daum\xe9",type:"Talk"},{paper_id:7,session_id:0,paper_order:0,title:"Dunning-Kruger Effect Can Hinder Appropriate Reliance on AI Systems",authors:"Gaole He, Lucie Kuiper and Ujwal Gadiraju",type:"Talk"},{paper_id:8,session_id:2,paper_order:1,title:"Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making",authors:"Jakob Schoeffer, Maria De-Arteaga and Niklas Kuehl",type:"Talk"},{paper_id:13,session_id:1,paper_order:0,title:"Does More Advice Help? The Effects of Second Opinions from Peers in AI-Assisted Decision Making",authors:"Zhuoran Lu, Dakuo Wang and Ming Yin",type:"Talk"},{paper_id:14,session_id:0,paper_order:1,title:"Introducing the trustworthiness assessment model and its implications for research on trust in artificial intelligence",authors:"Nadine Schlicker and Markus Langer",type:"Talk"},{paper_id:17,session_id:0,paper_order:2,title:"Chatbots as decision aids: investigating reliance in Human-Chatbot collaboration vs. Human-Human collaboration",authors:"Cl\xe9lie Amiot, Fran\xe7ois Charoy and J\xe9r\xf4me Dinet",type:"Talk"},{paper_id:18,session_id:1,paper_order:1,title:"Team At Your Service: Can Multiple Conversational Agents Increase Functional Specificity in Automated Driving?",authors:"Dinara Talypova and Philipp Wintersberger",type:"Talk"},{paper_id:34,session_id:1,paper_order:2,title:"Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-text Rationales",authors:"Brihi Joshi, Ziyi Liu, Sahana Ramnath, Aaron Chan, Zhewei Tong, Qifan Wang, Yejin Choi and Xiang Ren",type:"Talk"},{paper_id:37,session_id:0,paper_order:3,title:"Measuring, Predicting, and Leveraging Trust for Proactive Dialog in Human-AI Teams",authors:"Matthias Kraus",type:"Talk"},{paper_id:6,session_id:-1,paper_order:-1,title:"Distrust in (X)AI - Measurement Artifact or Distinct Construct?",authors:"Nicolas Scharowski and Sebastian A.C. Perrig",type:"Poster"},{paper_id:9,session_id:-1,paper_order:-1,title:"Humans, AI, and Context: Understanding End-Users\u2019 Trust in a Real-World Computer Vision Application",authors:"Sunnie S. Y. Kim, Elizabeth Watkins, Olga Russakovsky, Ruth Fong and Andr\xe9s Monroy-Hern\xe1ndez",type:"Poster"},{paper_id:22,session_id:-1,paper_order:-1,title:"Designing AI for Appropriation Will Calibrate Trust",authors:"Zelun Tony Zhang, Yuanting Liu and Andreas Butz",type:"Poster"},{paper_id:23,session_id:2,paper_order:2,title:"Addressing Trust Repair for AI Ethicality: The Influence of Team Role and Violation Type",authors:"Beau Schelble, Subhasree Sengupta, Alyssa Williams and Nathan McNeese",type:"Talk"},{paper_id:36,session_id:-1,paper_order:-1,title:"Co-Design of Autonomous Drones for Interactions with Bystanders",authors:"Eyal Ginosar, Susanna Kraemer, Marion Koelle, Heiko M\xfcller, Susanne Boll and Jessica Cauchard",type:"Poster"},{paper_id:44,session_id:-1,paper_order:-1,title:"Chronic Heart Patients Perspectives on 30-Day ML-based Predictions: Exploring Implications for Self-Care Practice and Patient-Physician Collaboration",authors:"Tariq Andersen, Stina Matthiesen and Emil Vogt S\xf8rensen",type:"Poster"},{paper_id:27,session_id:1,paper_order:3,title:"I Think You Might Like This': Exploring Effects of Confidence Signal Patterns on Trust in and Reliance on Conversational Recommender Systems",authors:"Marissa Radensky, Julie Anne S\xe9guin, Jang Soo Lim, Kristen Olson and Robert Geiger",type:"Talk"},{paper_id:29,session_id:-1,paper_order:-1,title:"Human and AI Trust: Trust Attitude Measurement Instrument Development",authors:"Retno Larasati, Anna De Liddo and Enrico Motta",type:"Poster"},{paper_id:30,session_id:-1,paper_order:-1,title:"Human-AI Trust Calibration Should Be Contextual and Continuous",authors:"Steven R. Gomez, Kevin K. Nam, Kimberlee Chestnut Chang, Gregg Marcus and Erin K. Chiou",type:"Poster"},{paper_id:39,session_id:-1,paper_order:-1,title:"A Task-based Metric for Measuring Trust in Autonomous Robots for Everyday Activities",authors:"Rachel Ringe and Robert Porzel",type:"Poster"},{paper_id:31,session_id:-1,paper_order:-1,title:"Evaluating User Trust in Active Learning Systems Through Query Policy and Uncertainty Visualization",authors:"Ian Thomas and Danielle Szafir",type:"Poster"},{paper_id:35,session_id:-1,paper_order:-1,title:"Eyes Are the Windows to AI Reliance: Towards Real-Time Human-AI Reliance Assessment",authors:"Shiye Cao, Shichang Ke, Yanyan Mo, Anqi Liu and Chien-Ming Huang",type:"Poster"},{paper_id:42,session_id:-1,paper_order:-1,title:"You haven't changed a bit! Initial Findings from a Bibliometric Analysis of Two Decades of Empirical Trust in AI Research",authors:"Michaela Benk, Sophie Kerstan and Andrea Ferrario",type:"Poster"},{paper_id:4,session_id:-1,paper_order:-1,title:"The Duet of Representations and How Explanations Exacerbate It",authors:"Charles Wan, Rodrigo Belo, Leid Zejnilovic and Susana Lavado",type:"Poster"},{paper_id:26,session_id:-1,paper_order:-1,title:"Simplicity is Complexity Resolved: Considering Task Complexity in Empirical HC(X)AI Studies",authors:"Sara Salimzadeh and Ujwal Gadiraju",type:"Poster"},{paper_id:41,session_id:-1,paper_order:-1,title:"Trust and Reliance in Compositional Control Teams",authors:"Kazuhiko Momose, Troy Weekes, Thomas Eskridge and Daniel Kidwell",type:"Poster"},{paper_id:45,session_id:-1,paper_order:-1,title:"Background Explanations Reduce User's Over-reliance on AI: A Case Study on Multi-Hop Question Answering",authors:"Navita Goyal, Eleftheria Briakou, Marine Carpuat and Hal Daum\xe9 III",type:"Poster"},{paper_id:12,session_id:-1,paper_order:-1,title:"Responsible Human-AI Teaming: Interface Designs to Promote Bias Awareness in Human-AI Fact-checking Teams",authors:"Caitlin Lancaster, Heba Aly, Subhasree Sengupta and Nathan McNeese",type:"Poster"}],announce:Object(A.jsxs)("div",{children:["Our"," ",Object(A.jsx)(p.b,{exact:!0,to:"/cfp",children:"Call for Papers"})," ","is open! Accepted papers are ",Object(A.jsx)("b",{children:"NON-ARCHIVAL"})," and you can still submit to other places; We also welcome ",Object(A.jsx)("b",{children:"shortened, encore submission"})," of highly-relevant conference/journal papers pubslished elsewhere!"]})},Q={contact:"trait2022@easychair.org",timezone:"Central Daylight Time (CDT) / UTC-5, New Orleans Time",acronym:"TRAIT",year:"2022",fullName:"Workshop on Trust and Reliance in AI-Human Teams",description:Object(A.jsxs)(A.Fragment,{children:[Object(A.jsxs)("p",{children:["As humans increasingly interact (and even collaborate) with AI systems during decision-making, creative exercises, and other tasks,appropriatetrust and reliance are necessary to ensure proper usage and adoption of these systems. Specifically, people should understand when to trust or rely on an algorithm's outputs and when to override them. While significant research focus has aimedto measure and promote trust in human-AI interaction, the field lacks synthesized definitions and understanding of results acrosscontexts. Indeed, conceptualizing trust and reliance, and identifying the best ways to measure these constructs and effectively shapethem in human-AI interactions remains a challenge.This workshop aims to"," ",Object(A.jsx)("b",{className:"text-highlight",children:"establish building appropriate trust and reliance on (imperfect) AI systems as a vital, yet under-explored research problem."})]}),Object(A.jsxs)("p",{children:[" ","The workshop will provide a venue for exploring three broad aspects related to human-AI trust:"," "]}),Object(A.jsxs)("ul",{children:[Object(A.jsxs)("li",{children:["How do we clarify"," ",Object(A.jsx)("span",{className:"text-highlight",children:"definitions and frameworks"})," ","relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)?"]}),Object(A.jsxs)("li",{children:["How do we ",Object(A.jsx)("span",{className:"text-highlight",children:"measure"})," trust and reliance?"]}),Object(A.jsxs)("li",{children:["How do we ",Object(A.jsx)("span",{className:"text-highlight",children:"shape"})," trust and reliance?"," "]})]}),Object(A.jsx)("p",{children:"As these problems and solutions involving humansand AI are interdisciplinary in nature, we invite participants with expertise in HCI, AI, ML, psychology, and social science, or otherrelevant fields to foster closer communications and collaboration between multiple communities."}),Object(A.jsxs)("p",{children:["The workshop will be ",Object(A.jsx)("b",{className:"text-highlight",children:"hybrid"}),". Participants can choose to come to New Orleans or participant online."]})]}),backgroundImg:"background.png",confLogoImg:"chi2022.png",logoImg:"logo.png",logoWithWord:"logo_word.png",confName:"CHI"},X={overview:Q,organizers:[{name:"Gagan Bansal",affliation:"University of Washington",webpage:"https://homes.cs.washington.edu/~bansalg/",img:"gagan.png",twitter:"https://twitter.com/bansalg_",description:"Gagan is a Ph.D. candidate in the Allen School of Computer Science and Engineering at the University of Washington, Seattle. He is part of the UW Lab for Human-AI Interaction and conducts interdisciplinary research on Artificial Intelligence and Human-Computer Interaction with focus on developing human-centered AI systems for augmenting people."},{name:"Alison Smith-Renner",affliation:"Dataminr",webpage:"https://alisonmsmith.github.io/",twitter:"https://twitter.com/alison_m_smith",img:"alison.png",description:"Alison is a Senior Research Scientist at Dataminr. Her research interests lie at the intersection of AI and HCI, focusing on transparency and control for human-in-the-loop systems to engender appropriate trust and improve human performance. Alison received her Ph.D. from the University of Maryland, College Park. She has organized various workshops on explainable AI and human-centered ML, including at IUI, CHI, and TEI, and she has held senior committee roles at IUI."},{name:"Zana Bu\xe7inca",affliation:"Harvard University",twitter:"https://twitter.com/ZanaBucinca",webpage:"https://hci.seas.harvard.edu/people/zana-bu%C3%A7inca",img:"zana.png",description:"Zana is a Ph.D. Candidate at Harvard University. Her research lies at the intersection of Human-Computer Interaction and Artificial Intelligence. Informed by cognitive science theories, Zana designs, builds, and evaluates AI for decision-making support."},{name:"Tongshuang (Sherry) Wu",twitter:"https://twitter.com/tongshuangwu",affliation:"University of Washington",webpage:"https://homes.cs.washington.edu/~wtshuang/",img:"sherry.png",description:"Sherry is a Ph.D. Candidate at the University of Washington, Seattle. Her research lies at the intersection of Human-Computer Interaction and Natural Language Processing, aiming to support humans interacting with imperfect AIs, by debugging and correcting AIs interactively. Her work improves system transparency and controllability in human-AI collaborations, and encourages global understanding and refinement in model analysis."},{name:"Ken Holstein",twitter:"https://twitter.com/d19fe8",affliation:"Carnegie Mellon University",webpage:"https://www.thecoalalab.com/kenholstein",img:"kenneth.png",description:"Ken is an Assistant Professor in Human-Computer Interaction at Carnegie Mellon University. His research interests lie at the intersection of HCI, AI, design, and cognitive science, focusing on the design, development, and evaluation of human-AI collaborative systems in complex social contexts."},{name:"Jessica Hullman",twitter:"https://twitter.com/JessicaHullman",affliation:"Northwestern University",webpage:"http://users.eecs.northwestern.edu/~jhullman/",img:"jessica.png",description:"Jessica is an Associate Professor of Computer Science at Northwestern University. Her research looks at how to design, evaluate, coordinate, and think about visual representations of data and model predictions for inference, decision making, and communication, including the effects of visualizing uncertainty on belief updating and potential for behaviorally induced feedback loops in visualizing model predictions in strategic settings."},{name:"Simone Stumpf",twitter:"https://twitter.com/DrSimoneStumpf",affliation:"University of Glasgow",webpage:"https://www.gla.ac.uk/schools/computing/staff/simonestumpf/",img:"simone.png",description:"Simone Stumpf is a Reader in Responsible and Interactive AI at University of Glasgow, UK. She has a long-standing research focus on user interactions with machine learning systems. Her work has contributed to shaping the field of Explainable AI (XAI) through the Explanatory Debugging approach to interactive machine learning, providing design principles for crafting explanations. She is a member of the organising committee of the ExSS workshop at IUI, and has held senior committee roles at CHI, IUI and EICS conferences."}],cfp:{description:"As humans increasingly interact with AI systems during decision-making, creative tasks, and other workflows, appropriate trust and reliance are necessary to ensure proper usage and adoption of these systems. For example, people should understand when to trust or rely on an algorithm\u2019s outputs and when to override them. While significant research focus has aimed to measure and promote trust in human-AI interaction, the field lacks synthesized results across contexts, formalized key concepts, and definitions. The workshop will provide a venue to explore three broad aspects related to human-AI trust: (1) How do we clarify definitions and frameworks relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)? (2) How do we measure trust and reliance? And, (3) How do we shape trust and reliance? ",themes:["Definitions of trust and reliance","Human-human trust and lessons from social sciences","Qualitative (e.g., user reflection) and quantitative methods (e.g., usage, adoption, team performance, etc.) for evaluating trust and reliance.","Tradeoffs with other objectives (e.g., team performance, creativity, etc)","Solutions (and their limitations) for promoting appropriate trust (e.g., XAI, control mechanisms, human agency, communicating uncertainty etc).","Safety mechanisms for when trust is broken."],dates:[{date:"February 24, 2022, 11:59 PM (Anywhere on Earth)",isPassed:!0,type:"Submission",description:"Submission will be reviewed by PC members, in a double-blind manner."},{date:"March 14, 2022",type:"Notification",isPassed:!0},{date:"April 11, 2022",type:"Camera ready",isPassed:!0,description:"Accepted papers will be non-archival, and will be posted on this website & shared via social media."},{date:"April 30, 2022 (Hybrid)",type:"Workshop",isPassed:!1,description:"At least one author must register and attend the hybrid workshop."}],submit:{platform:{name:"EasyChair",url:"https://easychair.org/conferences/?conf=trait2022"},format:Object(A.jsxs)("span",{children:[" ","ACM ",Object(A.jsx)("b",{children:"single"})," column, ",Object(A.jsx)("b",{children:"2-10"})," pages, excluding references, fully anonymized. [",Object(A.jsx)("a",{href:"https://www.acm.org/binaries/content/assets/publications/taps/acm_submission_template.docx",children:"Word"}),"][",Object(A.jsx)("a",{href:"https://www.acm.org/binaries/content/assets/publications/consolidated-tex-template/acmart-primary.zip",children:"LaTeX"}),"][",Object(A.jsx)("a",{href:"https://www.overleaf.com/latex/templates/acm-conference-proceedings-master-template/pnrfvrrdbfwt",children:"Overleaf"}),"] If you use latex, please use: ",Object(A.jsx)("code",{children:"documentclass [manuscript, review, anonymous] {acmart}"})]}),type:'Position paper; Summarize existing research; Provide industry perspective; In-progress work; "encore" submissions of highly-relevant conference/journal papers.'}},pcs:[{name:"Zahra Ashkortab",affiliation:"IBM Research"},{name:"Michael Bernstein",affiliation:"Stanford University"},{name:"Jim Chen",affiliation:"University of Washington"},{name:"Erin Chiou",affiliation:"ASU Adapt Lab"},{name:"Ian Covert",affiliation:"University of Washington"},{name:"Hal Daume III",affiliation:"University of Maryland"},{name:"Maria De-Arteaga",affiliation:"UT Austin"},{name:"Victor Dibia",affiliation:"Microsoft Research"},{name:"Fan Du",affiliation:"Adobe Research"},{name:"Krzysztof Gajos",affiliation:"Harvard University"},{name:"Elena Glassman",affiliation:"Harvard University"},{name:"Ella Glikson",affiliation:"Bar Ilan University"},{name:"Shi Feng",affiliation:"University of Maryland"},{name:"Matthew Kay",affiliation:"Northwestern University"},{name:"Maia Jacobs",affiliation:"Northwestern University"},{name:"Alon Jacovi",affiliation:"Bar Ilan University"},{name:"Joseph Janizek",affiliation:"University of Washington"},{name:"Retno Larasati",affiliation:"The Open University"},{name:"Vera Liao",affiliation:"Microsoft Research"},{name:"Brian Lim",affiliation:"National University of Singapore"},{name:"Tim Miller",affiliation:"University of Melbourne"},{name:"Hussein Mozannar",affiliation:"MIT"},{name:"Ishan Nigam",affiliation:"UT Austin"},{name:"Marissa Radensky",affiliation:"University of Washington"},{name:"Gonzalo Ramos",affiliation:"Microsoft Research"},{name:"Jenn Wortman Vaughan",affiliation:"Microsoft Research"},{name:"Jakob Schoeffer",affiliation:"Karlsruhe Institute of Technology"},{name:"Ben Shneiderman",affiliation:"University of Maryland"},{name:"Tom Williams",affiliation:"Colorado School of Mines"},{name:"Michael Terry",affiliation:"Google Research"},{name:"Ming Yin",affiliation:"Purdue University"},{name:"Tony Zhang",affiliation:"Fortiss"},{name:"Joyce Zhou",affiliation:"Cornell University"}],schedule:[{start:"09:00",end:"09:15",title:"Welcome",leader:"Gagan Bansal and Alison Smith-Renner",format:"Virtual (pre-recorded)",type:"break"},{start:"09:15",end:"10:20",title:"Keynote: Managing and measuring trust in human-AI teams (Prof. John D. Lee)",leader:"Kenneth Holstein",format:"Virtual (live)",type:"keynote",description:"Despite the rapid growth of AI, there is still a lack of understanding about how humans trust and rely on these systems. As AI becomes more sophisticated, it becomes difficult to determine where the AI interaction ends and the human interaction begins. This makes it difficult to determine who or what we are trusting, and who or what is controlling these interactions and influencing trust. I discuss three themes to establish a better understanding of trust in AI: blurring boundaries as AI moves from tool to teammate; challenges in defining and aligning goals; and the difference between trust in AI and trusting AI. These themes suggest new approaches for measuring and managing trust. Ongoing challenges include understanding how adapt these approaches to different contexts and populations."},{start:"10:20",end:"10:55",title:"Paper Session 1: Frameworks & Measuring Trust and Reliance",sessionId:0,leader:"Simone Stumpf",format:"Virtual (pre-recorded), slack Q&A",type:"paper"},{start:"10:55",end:"11:15",title:"Coffee break",format:"",type:"break"},{start:"11:15",end:"11:50",sessionId:1,title:"Paper Session 2: Factors and Strategies for Shaping Trust and Reliance",leader:"Sherry Tongshuang Wu",format:"Virtual (pre-recorded), slack Q&A",type:"paper"},{start:"11:50",end:"12:30",sessionId:2,title:"Paper Session 3: Understanding User Needs and New Perspectives for Trust and Reliance",leader:"Gagan Bansal",format:"Virtual (pre-recorded), slack Q&A",type:"paper"},{start:"12:30",end:"14:00",title:"Lunch",format:"on your own",type:"break"},{start:"14:00",end:"15:00",title:"Group activity 1 (40 min) + Results (20 mins)",leader:"Kenneth Holstein and Zana Bu\xe7inca",format:"Hybrid",type:"group"},{start:"15:00",end:"15:45",title:"Group activity 2 (30 min) + Results (15 mins)",leader:"Kenneth Holstein and Zana Bu\xe7inca",format:"Hybrid",type:"group"},{start:"15:45",end:"16:00",title:"Coffee break",format:"",type:"break"},{start:"16:00",end:"16:45",title:"Panel",leader:"Jessica Hullman",format:"Virtual (live)",type:"panel",description:"With Saleema Amershi, Maria De-Arteaga, Krzystof Gajos, and Tim Miller"},{start:"16:45",end:"17:00",title:"Closing remarks",leader:"Gagan Bansal and Alison Smith-Renner",format:"Virtual (live)",type:"break"}],speakers:[{name:"John D. Lee",affliation:"University of Wisconsin-Madison",webpage:"https://directory.engr.wisc.edu/ie/Faculty/Lee_John/",img:"john_lee.png",type:"keynote",description:"Dr. John D. Lee is the Emerson Electric Professor at the University of Wisconsin-Madison. He investigates the issues of human-automation interaction, particularly trust in automation. John has investigated trust in domains that include UAVs, maritime operations, highly automated vehicles, and deep space exploration. His work also involves assessing interface and interaction methods to enhance trust calibration, as well as statistical approaches to assess trust and user state estimation. He helped to edit the Handbook of Cognitive Engineering, the APA Handbook of Human Systems Integration, and is also a co-author of a popular textbook: Designing for People: An introduction to human factors engineering. This research has been funded by NSF, ONR, NHTSA, NASA, Nissan, Toyota, Honda, and GM."},{name:"Saleema Amershi",affliation:"Microsoft Research",webpage:"https://www.microsoft.com/en-us/research/people/samershi/",img:"saleema.jpg",type:"panelist",description:"Dr. Saleema Amershi is a Senior Principal Research Manager at Microsoft Research where she leads the Human-AI eXperiences (HAX) team, building tools for creating responsible AI experiences. She also currently co-chairs Microsoft's Aether Working Group on Human-AI Interaction and Collaboration. Aether is Microsoft\u2019s advisory committee on responsible and ethical AI. Her research focuses on helping people create effective and responsible AI user experiences. Her recent work includes leading Microsoft\u2019s effort to develop general Guidelines for Human-AI Interaction, a unified and validated set of guidelines to establish a foundation for human-AI interaction Design. Throughout the years, she has developed tools and methodologies to support practitioners in designing and building AI-based products and services, including general purpose platforms and visualizations for data scientists building predictive models, and application specific techniques for supporting end-users interacting with AI-systems in their everyday lives."},{name:"Maria De-Arteaga",type:"panelist",affliation:"University of Texas at Austin",webpage:"https://mariadearteaga.com/",img:"maria_dearteaga.jpg",description:"Dr. Maria De-Arteaga is an Assistant Professor at the Information, Risk and Operation Management Department at the University of Texas at Austin, where she is also a core faculty member in the Machine Learning Laboratory and a Good Systems researcher. She holds a joint PhD in Machine Learning and Public Policy from Carnegie Mellon University. Her research focuses on the risks and opportunities of using machine learning to support experts\u2019 decisions in high-stakes settings, with a particular interest in algorithmic fairness and human-AI collaboration. Her work has received best paper awards at WITS\u201921, NAACL\u201919 and Data for Policy\u201916, and research awards from Google and Microsoft Research."},{name:"Krzysztof Gajos",type:"panelist",affliation:"Harvard University",webpage:"http://www.eecs.harvard.edu/~kgajos/",img:"krzysztof.png",description:"Krzysztof Gajos is a Gordon McKay professor of Computer Science at the Harvard Paulson School of Engineering and Applied Sciences. Krzysztof\u2019s current interests include 1. Principles and applications of intelligent interactive systems; 2. Tools and methods for behavioral research at scale (e.g., LabintheWild.org); and 3. Design for equity and social justice. He has also made contributions in the areas of accessible computing, creativity support tools, social computing, and health informatics. Prior to arriving at Harvard, Krzysztof was a postdoctoral researcher at Microsoft Research. He received his Ph.D. from the University of Washington and his M.Eng. and B.Sc. degrees from MIT. From 2013 to 2016 Krzysztof was a coeditor-in-chief of the ACM Transactions on Interactive Intelligent Systems (ACM TiiS), he was the general chair of ACM UIST 2017, and he is currently a program co-chair of the 2022 ACM Conference on Intelligent User Interfaces. His work was recognized with best paper awards at ACM CHI, ACM COMPASS, and ACM IUI. In 2019, his received the Most Impactful Paper Award at ACM IUI for his work on automatically generating personalized user interfaces."},{name:"Tim Miller",type:"panelist",affliation:"University of Melbourne",webpage:"https://people.eng.unimelb.edu.au/tmiller/",img:"tim_miller.png",description:"Dr. Tim Miller is a Professor in the School of Computing and Information Systems at The University of Melbourne, and Co-Director for the Centre of AI and Digital Ethics (CAIDE). His primary area of expertise is in artificial intelligence, with particular emphasis on Human-AI interaction and collaboration; Explainable Artificial Intelligence (XAI); Decision making in complex, multi-agent environments; and Reasoning about action and knowledge. His work is at the intersection of artificial intelligence, interaction design, and cognitive science/psychology. His areas of education expertise is in artificial intelligence, software engineering, and technology innovation. He has extensive experience developing novel and innovative solution with industry and defence collaborators."}],papers:[{paper_id:49,session_id:0,paper_order:0,title:"Under-reliance or misalignment? How proxy outcomes limit measurement of appropriate reliance in AI-assisted decision-making",authors:"Luke Guerdan, Kenneth Holstein and Steven Wu",type:"long",is_encore:!1},{paper_id:47,session_id:1,paper_order:0,title:"Shaping Trust in Machine Translation Suggestions Through AI-Assisted Context Building",authors:"Jordan Huffaker and Sai Gouravajhala",type:"long",is_encore:!1},{paper_id:19,session_id:2,paper_order:3,title:"Building Trust by Supporting Situation Awareness: Exploring Pilots' Design Requirements for Decision Support Tools",authors:"Cara Storath, Zelun Tony Zhang, Yuanting Liu and Heinrich Hussmann",type:"long",is_encore:!1},{paper_id:55,session_id:0,paper_order:1,title:"Should I Follow AI-based Advice? Measuring Appropriate Reliance in Human-AI Decision-Making",authors:"Max Schemmer, Patrick Hemmer, Niklas K\xfchl, Carina Benz and Gerhard Satzger",type:"long",is_encore:!1},{paper_id:28,session_id:2,paper_order:2,title:"Addressing the Spread of Trust and Distrust in Distributed Human-AI Teaming Constellations",authors:"Beau Schelble, Christopher Flathmann, Matthew Scalia, Shiwen Zhou, Christopher Myers, Nathan McNeese, Jamie Gorman and Guo Freeman",type:"long",is_encore:!1},{paper_id:29,session_id:1,paper_order:1,title:"Impact of Awareness Cues on Trust in Human-AI Shared Control",authors:"Gabriele Cimolino, Carl Gutwin and T.C. Nicholas Graham",type:"long",is_encore:!1},{paper_id:43,session_id:1,paper_order:2,title:"Exploring How Anomalous Model Input and Output Alerts Affect Decision-Making in Healthcare",authors:"Marissa Radensky, Dustin Burson, Rajya Bhaiya and Daniel Weld",type:"long",is_encore:!1},{paper_id:59,session_id:1,paper_order:3,title:"The Disagreement Problem in Explainable Machine Learning: A Practitioner's Perspective",authors:"Satyapriya Krishna, Tessa Han, Alex Gu, Javin Pombra, Shahin Jabbari, Zhiwei Steven Wu and Himabindu Lakkaraju",type:"long",is_encore:!1},{paper_id:52,session_id:2,paper_order:1,title:"The Look of Trust: How Does Physical Embodiment Shape Trust in Human-Agent Interaction?",authors:"Angel Hsing-Chi Hwang",type:"long",is_encore:!1},{paper_id:26,session_id:2,paper_order:0,title:"Vulnerability, Trust, and AI",authors:"Ahmer Arif and Os Keyes",type:"long",is_encore:!1},{paper_id:11,session_id:0,paper_order:2,title:"MATCH: A Conceptual Model on Trust Judgments in AI Towards Designing for Responsible Trust",authors:"Q. Vera Liao and S. Shyam Sundar",type:"short",is_encore:!1},{paper_id:21,session_id:0,paper_order:3,title:"The Value of Measuring Trust in AI \u2013 A Socio-Technical System Perspective",authors:"Michaela Benk, Suzanne Tolmeijer, Florian von Wangenheim and Andrea Ferrario",type:"short",is_encore:!1},{paper_id:25,session_id:0,paper_order:4,title:"Behavioral Measures of Trust in Human-autonomy Teams",authors:"Daniel Gonzalez, David Piorkowski and David Mendonca",type:"short",is_encore:!1},{paper_id:33,session_id:2,paper_order:4,title:"Trust and explainability as tools for improving automated writing evaluation",authors:"Maria Goldshtein, Erin Chiou, Amin Alhashim and Rod Roscoe",type:"short",is_encore:!1},{paper_id:45,session_id:1,paper_order:4,title:"How Can AI Earn Trust of System Administrators in the IT-Security Domain?",authors:"Daria Soroko, Gian-Luca Savino and Nicholas Gray",type:"short",is_encore:!1},{paper_id:46,session_id:0,paper_order:5,title:"Review: Mathematical Models for Trust in Human-Automation Interactions",authors:"Lucero Rodriguez Rodriguez, Carlos Bustamante Orellana, Yun Kang, Erin Chiou and Lixiao Huang",type:"short",is_encore:!1},{paper_id:53,session_id:0,paper_order:6,title:"Perceive, Understand & Predict - Empirical Indication for Facets in Subjective Information Processing Awareness",authors:"Tim Schrills, Mona Bickel, Susanne Kargl and Thomas Franke",type:"short",is_encore:!1},{paper_id:48,session_id:1,paper_order:5,title:"Beyond General Purpose Machine Translation: The Need for Context-specific Empirical Research to Design for Appropriate User Trust",authors:"Wesley Hanwen Deng, Nikita Mehandru, Samantha Roberston and Niloufar Salehi",type:"short",is_encore:!1},{paper_id:23,session_id:2,paper_order:5,title:"Understanding non-adoption of ``optimal'' algorithmic tips for problem-solving: how people view and use tips and the barriers they encounter",authors:"David Lee and Wichinpong Park Sinchaisri",type:"short",is_encore:!1},{paper_id:27,session_id:1,paper_order:6,title:"Doubting AI Predictions: Influence-Driven Second Opinion Recommendation",authors:"Maria De-Arteaga, Alexandra Chouldechova and Artur Dubrawski",type:"short",is_encore:!1},{paper_id:30,session_id:2,paper_order:6,title:"Trust in AI in Under-resourced Environments: Lessons from Local Journalism",authors:"Marianne Aubin Le Quere and Maurice Jakesch",type:"short",is_encore:!1},{paper_id:42,session_id:0,paper_order:12,title:"Towards a Framework for Evaluating Trust Based on User Confidence in Outcomes in the Human-AI Collaboration Setting",authors:"Submission        Joshua Boley, Katelyn Kozinski and Maoyuan Sun",type:"short",is_encore:!1},{paper_id:7,session_id:2,paper_order:12,title:"AI for human assessment: What do professional assessors need?",authors:"Riku Arakawa and Hiromu Yakura.",type:"short",is_encore:!1},{paper_id:40,session_id:0,paper_order:7,title:"Are we measuring trust correctly in explainability, interpretability, and transparency research?",authors:"Tim Miller",type:"short",is_encore:!1},{paper_id:57,session_id:2,paper_order:7,title:"Towards Understanding Trust and Reassurance in Human-Robot Teams: A User Study with a UV-C Disinfection Robot",authors:"Maria Jose Galvez Trigo, Joel Fischer, Horia Maior, Dominic Price, Pauline Leonard, Chira Tochia, Richard Hyde and Nicholas Watson.",type:"short",is_encore:!1},{paper_id:17,session_id:2,paper_order:8,title:"Towards a Framework for Trust in Clinical AI: Expanding the Unit of Analysis",authors:"Jacob Browne, Saskia Bakker, Bin Yu, Jeroen Raijmakers, Jon Pluyter, Nick Ruijs and Eva Deckers",type:"short",is_encore:!1},{paper_id:32,session_id:0,paper_order:8,title:"Exploring Trust Indicators in Human-Agent Conversation with Epistemic Network Analysis",authors:"Mengyao Li, Varshini Kamaraj and John Lee",type:"short",is_encore:!1},{paper_id:44,session_id:1,paper_order:7,title:"When Do XAI Methods Work? A Cost-Benefit Approach to Human-AI Collaboration",authors:"Helena Vasconcelos, Matthew J\xf6rke, Madeleine Grunde-McLaughlin, Ranjay Krishna, Tobias Gerstenberg and Michael Bernstein",type:"short",is_encore:!1},{paper_id:51,session_id:0,paper_order:9,title:"Towards a Generalized Scale to Measure Situational Trust in AI Systems",authors:"Lena Dolinek and Philipp Wintersberger",type:"short",is_encore:!1},{paper_id:13,session_id:2,paper_order:13,title:"User Trust on an Explainable AI-based Medical Diagnosis Support System",authors:"Yao Rong, Nora Castner, Efe Bozkir and Enkelejda Kasneci",type:"short",is_encore:!1},{paper_id:15,session_id:1,paper_order:10,title:"Walking on Eggshells: Using Analogies to Promote Appropriate Reliance in Human-AI Decision Making",authors:"Gaole He and Ujwal Gadiraju",type:"short",is_encore:!1},{paper_id:20,session_id:0,paper_order:10,title:"Trust and Reliance in XAI - Distinguishing Between Attitudinal and Behavioral Measures",authors:"Nicolas Scharowski, Sebastian A. C. Perrig, Nick von Felten and Florian Br\xfchlmann",type:"short",is_encore:!1},{paper_id:5,session_id:1,paper_order:11,title:"Teaching Humans When To Defer to a Classifier via Exemplars",authors:"Hussein Mozannar, Arvind Satyanarayan and David Sontag",type:"short",is_encore:!0},{paper_id:9,session_id:0,paper_order:13,title:"Dynamics of Human Trust in Recommender Systems",authors:"Jason Harman, John O'Donovan, Tarek Abdelzaher and Cleotilde Gonzalez",type:"short",is_encore:!0},{paper_id:12,session_id:2,paper_order:9,title:"Investigations of Performance and Bias in Human-AI Teamwork in Hiring",authors:"Andi Peng, Besmira Nushi, Emre Kiciman, Kori Inkpen and Ece Kamar",type:"short",is_encore:!0},{paper_id:14,session_id:1,paper_order:12,title:"Exploring the Effect of Value Similarity on Trust in Human-AI Interaction",authors:"Siddharth Mehrotra, Catholijn M. Jonker and Myrthe L. Tielman",type:"short",is_encore:!0},{paper_id:31,session_id:1,paper_order:13,title:"Do Exact Explanations Make a Difference? A Case Study Among Weight Management Experts",authors:"Glenn Fernandes, Arthur Choi, Maia Jacobs, Adnan Darwiche and Nabil Alshurafa",type:"short",is_encore:!1},{paper_id:36,session_id:0,paper_order:11,title:"Pragmatic delegation of work by humans and machines",authors:"Jordan Suchow and Jeffrey Nickerson",type:"short",is_encore:!1},{paper_id:37,session_id:2,paper_order:10,title:"Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support",authors:"Anna Kawakami, Venkatesh Sivaraman, Hao-Fei Cheng, Logan Stapleton, Yanghuidi Cheng, Diana Qing, Adam Perer, Zhiwei Steven Wu, Haiyi Zhu and Kenneth Holstein",type:"short",is_encore:!0},{paper_id:38,session_id:1,paper_order:8,title:"An Empirical Investigation of Reliance on AI-Assistance in a Noisy-Image Classification Task",authors:"Aakriti Kumar, Heliodoro Tejeda Lemus and Mark Steyvers",type:"short",is_encore:!1},{paper_id:58,session_id:2,paper_order:11,title:"Recognizing the Problem of High Trust",authors:"Shivani Kapania",type:"short",is_encore:!0},{paper_id:24,session_id:1,paper_order:9,title:"Trust and Reliance in Human-AI Collaborative Text Summarization",authors:"Ruijia Cheng, Alison Smith-Renner, Ke Zhang, Joel Tetreault and Alejandro Jaimes",type:"short",is_encore:!1}],announce:Object(A.jsxs)("div",{children:["Workshop registration is ",Object(A.jsx)("b",{children:"closed"}),". However, if you have already registered for it but ",Object(A.jsx)("b",{children:"have not joined the workshop Slack"}),", please email us at ",Object(A.jsx)("a",{href:"mailto:".concat(Q.contact),children:Q.contact})," to get access!"]})},q=Object(o.a)({palette:{primary:{main:l.a[700]},secondary:{main:d.a[700]}},typography:{button:{fontFamily:"Google Sans Display",textTransform:"none"}},overrides:{MuiFilledInput:{root:{backgroundColor:d.a[50],"&:hover":{backgroundColor:d.a[100]},"&.Mui-focused":{backgroundColor:d.a[100]}}},MuiButton:{contained:{boxShadow:"none","&:hover":{boxShadow:"none"},"&:disabled":{backgroundColor:d.a[600],color:d.a[200]}},containedPrimary:{backgroundColor:l.a[600],color:"white","&:hover":{backgroundColor:l.a[500],color:"white"}}}}}),$=function(){var e=[X,Y];return Object(A.jsx)(c.a,{theme:q,children:Object(A.jsx)(p.a,{children:Object(A.jsxs)("div",{className:"app",children:[Object(A.jsx)(k,{logo:Y.overview.logoImg}),Object(A.jsxs)(h.c,{children:[Object(A.jsx)(h.a,{path:"/:year/cfp",exact:!0,render:function(){return Object(A.jsx)(Z,{metas:e,types:["cfp"]})}}),Object(A.jsx)(h.a,{path:"/:year/schedule",exact:!0,render:function(){return Object(A.jsx)(Z,{metas:e,types:["schedule"]})}}),Object(A.jsx)(h.a,{path:"/:year/about",exact:!0,render:function(){return Object(A.jsx)(Z,{metas:e,types:["about","organizers","committee"]})}}),Object(A.jsx)(h.a,{path:"/:year/",render:function(){return Object(A.jsx)(Z,{metas:e,types:["about","organizers","committee"]})}})]}),Object(A.jsx)(V,{contact:Y.overview.contact})]})})})};r.render(Object(A.jsx)($,{}),document.getElementById("root"))}},[[85,1,2]]]);
//# sourceMappingURL=main.b0bb4769.chunk.js.map