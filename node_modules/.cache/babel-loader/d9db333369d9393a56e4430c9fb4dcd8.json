{"ast":null,"code":"const organizers = [{\n  name: \"Tongshuang (Sherry) Wu\",\n  affliation: \"University of Washington\",\n  webpage: \"https://homes.cs.washington.edu/~wtshuang/\",\n  img: \"sherry.png\",\n  description: \"Sherry Wu is a Ph.D. Candidate at the University of Washington, Seattle. \" + \"Her research lies at the intersection of Human-Computer Interaction \" + \"and Natural Language Processing, aiming to support humans interacting with imperfect AIs, \" + \"by debugging and correcting AIs interactively. Her work improves system transparency and \" + \"controllability in human-AI collaborations, and encourages global understanding and \" + \"refinement in model analysis.\"\n}, {\n  name: \"Gagan Bansal\",\n  affliation: \"University of Washington\",\n  webpage: \"https://homes.cs.washington.edu/~bansalg/\",\n  img: \"gagan.png\",\n  description: \"Gagan Bansal is a Ph.D. candidate in the Allen School of Computer Science and Engineering at the University of Washington, Seattle. He is part of the UW Lab for Human-AI Interaction and conducts interdisciplinary research on Artificial Intelligence and Human-Computer Interaction with focus on developing human-centered AI systems for augmenting people.\"\n}];\nconst cfp = {\n  description: \"As humans increasingly interact with AI systems during decision-making, creative tasks, and other workflows, appropriate trust and reliance are necessary to ensure proper usage and adoption of these systems. For example, people should understand when to trust or rely on an algorithm’s outputs and when to override them. While significant research focus has aimed to measure and promote trust in human-AI interaction, the field lacks synthesized results across contexts, formalized key concepts, and definitions. The workshop will provide a venue to explore three broad aspects related to human-AI trust: (1) How do we clarify definitions and frameworks relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)? (2) How do we measure trust and reliance? And, (3) How do we shape trust and reliance? \",\n  themes: [\"Definitions of trust and reliance\", \"Human-human trust and lessons from social sciences\"]\n};\nexport const Info2022 = {\n  organizers\n};","map":{"version":3,"sources":["/Users/tongshuangwu/sourcetree/chi-trait/src/stores/Info2022.ts"],"names":["organizers","name","affliation","webpage","img","description","cfp","themes","Info2022"],"mappings":"AAEA,MAAMA,UAAuB,GAAG,CAC9B;AACEC,EAAAA,IAAI,EAAE,wBADR;AAEEC,EAAAA,UAAU,EAAE,0BAFd;AAGEC,EAAAA,OAAO,EAAE,4CAHX;AAIEC,EAAAA,GAAG,EAAE,YAJP;AAKEC,EAAAA,WAAW,EACT,8EACA,sEADA,GAEA,4FAFA,GAGA,2FAHA,GAIA,sFAJA,GAKA;AAXJ,CAD8B,EAe9B;AACEJ,EAAAA,IAAI,EAAE,cADR;AAEEC,EAAAA,UAAU,EAAE,0BAFd;AAGEC,EAAAA,OAAO,EAAE,2CAHX;AAIEC,EAAAA,GAAG,EAAE,WAJP;AAKEC,EAAAA,WAAW,EACT;AANJ,CAf8B,CAAhC;AAyBA,MAAMC,GAAQ,GAAG;AACfD,EAAAA,WAAW,EACT,m0BAFa;AAGfE,EAAAA,MAAM,EAAE,CACN,mCADM,EAEN,oDAFM;AAHO,CAAjB;AASA,OAAO,MAAMC,QAAkB,GAAG;AAChCR,EAAAA;AADgC,CAA3B","sourcesContent":["import { CFP, Metadata, Organizer } from \"./Interfaces\";\n\nconst organizers: Organizer[] = [\n  {\n    name: \"Tongshuang (Sherry) Wu\",\n    affliation: \"University of Washington\",\n    webpage: \"https://homes.cs.washington.edu/~wtshuang/\",\n    img: \"sherry.png\",\n    description:\n      \"Sherry Wu is a Ph.D. Candidate at the University of Washington, Seattle. \" +\n      \"Her research lies at the intersection of Human-Computer Interaction \" +\n      \"and Natural Language Processing, aiming to support humans interacting with imperfect AIs, \" +\n      \"by debugging and correcting AIs interactively. Her work improves system transparency and \" +\n      \"controllability in human-AI collaborations, and encourages global understanding and \" +\n      \"refinement in model analysis.\",\n  },\n\n  {\n    name: \"Gagan Bansal\",\n    affliation: \"University of Washington\",\n    webpage: \"https://homes.cs.washington.edu/~bansalg/\",\n    img: \"gagan.png\",\n    description:\n      \"Gagan Bansal is a Ph.D. candidate in the Allen School of Computer Science and Engineering at the University of Washington, Seattle. He is part of the UW Lab for Human-AI Interaction and conducts interdisciplinary research on Artificial Intelligence and Human-Computer Interaction with focus on developing human-centered AI systems for augmenting people.\",\n  },\n];\n\nconst cfp: CFP = {\n  description:\n    \"As humans increasingly interact with AI systems during decision-making, creative tasks, and other workflows, appropriate trust and reliance are necessary to ensure proper usage and adoption of these systems. For example, people should understand when to trust or rely on an algorithm’s outputs and when to override them. While significant research focus has aimed to measure and promote trust in human-AI interaction, the field lacks synthesized results across contexts, formalized key concepts, and definitions. The workshop will provide a venue to explore three broad aspects related to human-AI trust: (1) How do we clarify definitions and frameworks relevant to human-AI trust and reliance (e.g., what does trust mean in different contexts)? (2) How do we measure trust and reliance? And, (3) How do we shape trust and reliance? \",\n  themes: [\n    \"Definitions of trust and reliance\",\n    \"Human-human trust and lessons from social sciences\",\n  ],\n};\n\nexport const Info2022: Metadata = {\n  organizers,\n};\n"]},"metadata":{},"sourceType":"module"}